---
title: "Big Data Homework"
author: "32152339 송준영"
date: "2020. 10. 26."
output:
  pdf_document: default
  html_document:
    css: bootstrap.css
---

```{r, include=FALSE}
# setting default options
knitr::opts_chunk$set(echo = TRUE)  # show R commands
```
<div style="margin-bottom:30px;">

</div>
이 R markdown template을 이용해서 중간과제를 제출하시면 됩니다.

* __"your_studentID(학번) name(이름)"__ 에 각자의 학번과 이름을 입력합니다.  
* 텍스트 데이터의 입력, 전처리를 위한 R 코드를 입력하고 각 R 코드에 대한 자세한 설명을 추가합니다.  

</div> 
<!--- R 코드와 설명을 아래에 입력합니다. --->
```{r}
library(rmarkdown)
library(stopwords)
library(textstem)

art=scan("http://www.gutenberg.org/files/63550/63550-0.txt",what = "character",encoding="UTF-8",sep="\n")
art[1:50]#해당 책의 메타데이터
art[300:350]#CHAPTER 라는 문자로 장이 구분됨
art[8800:8900]#THE END라는 문자로 본문이 끝남

art_chepter<-grep(art,pattern = "CHAPTER") #챕터별 인덱스 할당
art_end<-grep(art,pattern = "THE END") #본문의 마지막 구문 할당 
art_body<-art[(art_chepter[1]):art_end] #본문 할당
art_all<-paste(art_body,collapse=" ") # 하나의 긴 문장처럼 변환. 즉, 하나의 벡터로 변환


##preprocessing

#case-folding : 모든 알파벳을 소문자화 시킴. 모든 문자를 소문자화 시킨다면 의미적으로 변하는 단어가 있을 수 있으나, 이를 고려하면 너무 세부적인 튜닝이 필요하므로 그대로 진행함.
art_all<-tolower(art_all)

#removing punctuation except apostrophe and hyphen : '와 -가 제거된다면 문장의 의미가 완전 달라질 수 있기에 이를 제외하고 나머지 문장부호를 제거함.
art_all<-gsub(art_all,pattern = "([^[:alnum:][:blank:]'-])",replacement = "") 
#[^[:alnum:][:blank:]'-]의 의미 : [:alnum:](알파벳과 숫자)이거나 [:blank:](공백)이거나 '이거나 -면 제외하고 나머지를 제거하라. 

#removing "'s" : normalization을 위해 's를 제거함. 예를들어 joonyoung's와 joonyoung은 의미적으로 큰 차이가 없으므로 's를 제거함.
art_all<-gsub(art_all,pattern = "'s",replacement = "")

#tokenization : 공백을 기준으로 분리.
art_all<-unlist(strsplit(art_all," "))

#removing stopwords : 불용어를 제거함. 빈 요소도 제거.
art_all<-art_all[! art_all %in% c(stopwords(),"")]

#immatization: 원형복원. 사전에 적혀있는 단어들로 변환함. stemming을 사용할 수도 있으나 해당 글에서는 immatization이 적절할 것이라고 판단하여 이를 활용.
art_all<-lemmatize_strings(art_all)

#sorted frequency table : 빈도가 높은 단어들로 추측하자면 춤, 예술과 관련된 내용일 가능성이 높음.
art_all_table <- sort(table(art_all),decreasing = T)
head(art_all_table,10) 
```
<!--- 끝 --->  

<div style="margin-bottom:30px;">

</div>
위에서 얻어진 전처리 결과를 통계분석에 이용하려 할 때 발생할 수 있는 문제점에 대해 서술하시오. 

* -case-folding : 대문자가 가지고 있는 의미 혹은 CHAPTER와 같은 분석시 중요한 단어가 변환되었으므로 정보의 손실이 있을 수 있다. 즉 underfitting이 있을 수 있다. 해결방법으로는 다소 복잡하고 시간이 오래걸리나 gsub을통해 변환하는 방법이 있다.
* tokenization  : 복합어에 대한 전처리과정이 생략되었기 때문에 본래의 의미를 잃은 token들이 발생했을 가능성이 있다.
* lemmatizer : lemmatization을 진행했으므로 몇몇 단어는 본래의 의미를 잃었을 가능성이 있다. 하지만 normalization을 했으므로 분석에는 용이할 수 있는데 이러한 underfitting과 overfitting 경계에서 전처리 결과를 관찰하면서 그 경계를 적절히 찾아야 한다.
* stopwords : 빈도 내림차순으로 단어를 정렬하면 상위에 one, may, see등의 단어가 관찰되는데 이는 일반적인 문서에서 자주 쓰이는 단어이므로 stopwords 벡터에 포함시켜 제거한다면 해당 문서의 내용을 파악하기 용이할 수 있다.
</div> 